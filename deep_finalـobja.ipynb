{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "mUTntMgepAqn",
      "metadata": {
        "id": "mUTntMgepAqn"
      },
      "source": [
        "### پروژه درس یادگیری عمیق\n",
        "### سهیل حمزه بیگی\n",
        "### شماره دانشجویی: ۴۰۳۴۴۳۰۴۷\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tFUiy62101ar",
      "metadata": {
        "id": "tFUiy62101ar"
      },
      "source": [
        "### Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05N8XZ8c2DQH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05N8XZ8c2DQH",
        "outputId": "94f059ed-a917-458e-b52f-80ad87195db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep  3 09:51:43 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting diffusers==0.21.4\n",
            "  Downloading diffusers-0.21.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting accelerate==0.25.0\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers==0.21.4) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers==0.21.4) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.21.4) (0.34.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from diffusers==0.21.4) (8.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers==0.21.4) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.21.4) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers==0.21.4) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.21.4) (0.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.21.4) (2025.3.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.21.4) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.21.4) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.21.4) (1.1.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.4.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->diffusers==0.21.4) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.21.4) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.21.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.21.4) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.21.4) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.25.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0) (3.0.2)\n",
            "Downloading diffusers-0.21.4-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diffusers, accelerate\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.35.1\n",
            "    Uninstalling diffusers-0.35.1:\n",
            "      Successfully uninstalled diffusers-0.35.1\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.10.1\n",
            "    Uninstalling accelerate-1.10.1:\n",
            "      Successfully uninstalled accelerate-1.10.1\n",
            "Successfully installed accelerate-0.25.0 diffusers-0.21.4\n",
            "Collecting nerfacc\n",
            "  Downloading nerfacc-0.5.3-py3-none-any.whl.metadata (915 bytes)\n",
            "Collecting trimesh\n",
            "  Downloading trimesh-4.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Collecting objaverse==0.1.7\n",
            "  Downloading objaverse-0.1.7-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: imageio[ffmpeg] in /usr/local/lib/python3.12/dist-packages (2.37.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from objaverse==0.1.7) (2.32.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from objaverse==0.1.7) (2.2.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from objaverse==0.1.7) (18.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from objaverse==0.1.7) (4.67.1)\n",
            "Collecting loguru (from objaverse==0.1.7)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: fsspec>=2022.11.0 in /usr/local/lib/python3.12/dist-packages (from objaverse==0.1.7) (2025.3.0)\n",
            "Collecting gputil==1.4.0 (from objaverse==0.1.7)\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: rich>=12 in /usr/local/lib/python3.12/dist-packages (from nerfacc) (13.9.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from nerfacc) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.12/dist-packages (from trimesh) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio[ffmpeg]) (11.3.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.12/dist-packages (from imageio[ffmpeg]) (0.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from imageio[ffmpeg]) (5.9.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12->nerfacc) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12->nerfacc) (2.19.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->objaverse==0.1.7) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->objaverse==0.1.7) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->objaverse==0.1.7) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->objaverse==0.1.7) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->objaverse==0.1.7) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->objaverse==0.1.7) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (3.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12->nerfacc) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->nerfacc) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->nerfacc) (3.0.2)\n",
            "Downloading objaverse-0.1.7-py3-none-any.whl (32 kB)\n",
            "Downloading nerfacc-0.5.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trimesh-4.8.1-py3-none-any.whl (728 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=0daad404c6c23aa5cf42870c01c49fe4ab02b041e0f3f535401c3c3bcc9a28d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a8/b7/d8a067c31a74de9ca252bbe53dea5f896faabd25d55f541037\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil, trimesh, loguru, objaverse, nerfacc\n",
            "Successfully installed gputil-1.4.0 loguru-0.7.3 nerfacc-0.5.3 objaverse-0.1.7 trimesh-4.8.1\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (4.55.4)\n",
            "Collecting transformers<5.0.0,>=4.41.0\n",
            "  Downloading transformers-4.56.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (2.32.4)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0)\n",
            "  Downloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.41.0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.41.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.41.0) (1.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.41.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.41.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.41.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.41.0) (2025.8.3)\n",
            "Downloading transformers-4.56.0-py3-none-any.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m127.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m128.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.4\n",
            "    Uninstalling tokenizers-0.21.4:\n",
            "      Successfully uninstalled tokenizers-0.21.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.55.4\n",
            "    Uninstalling transformers-4.55.4:\n",
            "      Successfully uninstalled transformers-4.55.4\n",
            "Successfully installed tokenizers-0.22.0 transformers-4.56.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-09-03 09:52:29.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.github\u001b[0m:\u001b[36m_get_annotations\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mDownloading https://huggingface.co/datasets/allenai/objaverse-xl/resolve/main/github/github.parquet to objaverse_data/github/github.parquet\u001b[0m\n",
            "\u001b[32m2025-09-03 09:52:50.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36mget_annotations\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mDownloading https://huggingface.co/datasets/allenai/objaverse-xl/resolve/main/thingiverse/thingiverse.parquet to objaverse_data/thingiverse/thingiverse.parquet\u001b[0m\n",
            "\u001b[32m2025-09-03 09:52:58.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.smithsonian\u001b[0m:\u001b[36mget_annotations\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mDownloading https://huggingface.co/datasets/allenai/objaverse-xl/resolve/main/smithsonian/smithsonian.parquet to objaverse_data/smithsonian/smithsonian.parquet\u001b[0m\n",
            "\u001b[32m2025-09-03 09:52:59.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.sketchfab\u001b[0m:\u001b[36m_get_annotations\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mDownloading https://huggingface.co/datasets/allenai/objaverse-xl/resolve/main/sketchfab/sketchfab.parquet to objaverse_data/sketchfab/sketchfab.parquet\u001b[0m\n",
            "\u001b[32m2025-09-03 09:53:03.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.sketchfab\u001b[0m:\u001b[36mdownload_objects\u001b[0m:\u001b[36m508\u001b[0m - \u001b[1mFound 0 objects already downloaded\u001b[0m\n",
            "\u001b[32m2025-09-03 09:53:03.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.sketchfab\u001b[0m:\u001b[36mdownload_objects\u001b[0m:\u001b[36m529\u001b[0m - \u001b[1mDownloading 3 new objects across 4 processes\u001b[0m\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.34it/s]\n",
            "\u001b[32m2025-09-03 09:53:05.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.github\u001b[0m:\u001b[36mdownload_objects\u001b[0m:\u001b[36m602\u001b[0m - \u001b[1mProvided 5 repoIds with 5 objects to process.\u001b[0m\n",
            "\u001b[32m2025-09-03 09:53:05.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.github\u001b[0m:\u001b[36mdownload_objects\u001b[0m:\u001b[36m614\u001b[0m - \u001b[1mFound 5 repoIds not yet downloaded. Downloading now...\u001b[0m\n",
            "Grouping objects by repository: 100%|██████████| 5/5 [00:00<00:00, 344.44it/s]\n",
            "Handling 3D object files: 100%|██████████| 1876/1876 [00:00<00:00, 17091.76it/s]\n",
            "Handling 3D object files: 100%|██████████| 512/512 [00:00<00:00, 8103.62it/s]\n",
            "Handling 3D object files: 100%|██████████| 579/579 [00:00<00:00, 12924.16it/s]\n",
            "Handling 3D object files: 100%|██████████| 265/265 [00:02<00:00, 121.34it/s]\n",
            "Handling 3D object files: 100%|██████████| 465151/465151 [02:38<00:00, 2929.21it/s]\n",
            "Downloading repositories: 100%|██████████| 5/5 [06:03<00:00, 72.78s/it] \n",
            "\u001b[32m2025-09-03 09:59:09.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36mdownload_objects\u001b[0m:\u001b[36m370\u001b[0m - \u001b[1mFound 0 Thingiverse objects downloaded\u001b[0m\n",
            "\u001b[32m2025-09-03 09:59:09.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36mdownload_objects\u001b[0m:\u001b[36m376\u001b[0m - \u001b[1mDownloading 7 Thingiverse objects with processes=4\u001b[0m\n",
            "Downloading Thingiverse Objects:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[32m2025-09-03 09:59:25.055\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36m_download_item\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mThingiverse file ID 12961177 could not get response from https://www.thingiverse.com/download:12961177\u001b[0m\n",
            "\u001b[32m2025-09-03 09:59:25.051\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36m_download_item\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mThingiverse file ID 3160602 could not get response from https://www.thingiverse.com/download:3160602\u001b[0m\n",
            "Downloading Thingiverse Objects:  14%|█▍        | 1/7 [00:15<01:31, 15.25s/it]\u001b[32m2025-09-03 09:59:25.063\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36m_download_item\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mThingiverse file ID 7882288 could not get response from https://www.thingiverse.com/download:7882288\u001b[0m\n",
            "\u001b[32m2025-09-03 09:59:25.070\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36m_download_item\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mThingiverse file ID 9167257 could not get response from https://www.thingiverse.com/download:9167257\u001b[0m\n",
            "\u001b[32m2025-09-03 09:59:40.267\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36m_download_item\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mThingiverse file ID 6885778 could not get response from https://www.thingiverse.com/download:6885778\u001b[0m\n",
            "Downloading Thingiverse Objects:  71%|███████▏  | 5/7 [00:30<00:11,  5.51s/it]\u001b[32m2025-09-03 09:59:40.273\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36m_download_item\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mThingiverse file ID 10096009 could not get response from https://www.thingiverse.com/download:10096009\u001b[0m\n",
            "\u001b[32m2025-09-03 09:59:40.293\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36m_download_item\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mThingiverse file ID 188164 could not get response from https://www.thingiverse.com/download:188164\u001b[0m\n",
            "Downloading Thingiverse Objects: 100%|██████████| 7/7 [00:30<00:00,  4.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 3 assets.\n",
            "Generated dummy 8 views for each of 15 assets\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install diffusers==0.21.4 accelerate==0.25.0\n",
        "!pip install nerfacc trimesh imageio[ffmpeg] matplotlib objaverse==0.1.7\n",
        "!pip install --upgrade \"transformers>=4.41.0,<5.0.0\"\n",
        "\n",
        "import objaverse.xl as oxl\n",
        "import objaverse\n",
        "import random, os\n",
        "\n",
        "\n",
        "save_dir = \"objaverse_data\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "num_procs = 4\n",
        "\n",
        "annotations = oxl.get_annotations(download_dir=save_dir)\n",
        "\n",
        "sample = annotations.sample(15).reset_index(drop=True)\n",
        "\n",
        "objects = oxl.download_objects(\n",
        "    objects=sample,\n",
        "    download_dir=save_dir,\n",
        "    processes=num_procs\n",
        ")\n",
        "\n",
        "print(\"Downloaded\", len(objects), \"assets.\")\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "out_root = \"dataset_objaverse\"\n",
        "os.makedirs(out_root, exist_ok=True)\n",
        "\n",
        "uids = list(objaverse.load_uids())\n",
        "sample_uids = random.sample(uids, 15)  # take 15 assets\n",
        "\n",
        "for idx, uid in enumerate(sample_uids):\n",
        "    asset_dir = os.path.join(out_root, f\"asset_{idx}\")\n",
        "    os.makedirs(asset_dir, exist_ok=True)\n",
        "    for view in range(8):\n",
        "        img = Image.new(\"RGB\", (128,128), (random.randint(0,255), random.randint(0,255), random.randint(0,255)))\n",
        "        d = ImageDraw.Draw(img)\n",
        "        d.text((10,60), f\"{uid[:6]} v{view}\", fill=(255,255,255))\n",
        "        img.save(os.path.join(asset_dir, f\"view_{view}.png\"))\n",
        "print(\"Generated dummy 8 views for each of 15 assets\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UVULKQX201lk",
      "metadata": {
        "id": "UVULKQX201lk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d401397-df21-41ac-9b92-9f94aef29a5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: objaverse in /usr/local/lib/python3.12/dist-packages (0.1.7)\n",
            "Requirement already satisfied: trimesh in /usr/local/lib/python3.12/dist-packages (4.8.1)\n",
            "Collecting pyrender\n",
            "  Downloading pyrender-0.1.45-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (2.37.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from objaverse) (2.32.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from objaverse) (2.2.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from objaverse) (18.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from objaverse) (4.67.1)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.12/dist-packages (from objaverse) (0.7.3)\n",
            "Requirement already satisfied: fsspec>=2022.11.0 in /usr/local/lib/python3.12/dist-packages (from objaverse) (2025.3.0)\n",
            "Requirement already satisfied: gputil==1.4.0 in /usr/local/lib/python3.12/dist-packages (from objaverse) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.12/dist-packages (from trimesh) (2.0.2)\n",
            "Collecting freetype-py (from pyrender)\n",
            "  Downloading freetype_py-2.5.1-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pyrender) (3.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from pyrender) (11.3.0)\n",
            "Collecting pyglet>=1.4.10 (from pyrender)\n",
            "  Downloading pyglet-2.1.8-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting PyOpenGL==3.1.0 (from pyrender)\n",
            "  Downloading PyOpenGL-3.1.0.zip (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pyrender) (1.16.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from pyrender) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->objaverse) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->objaverse) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->objaverse) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->objaverse) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->objaverse) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->objaverse) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->objaverse) (2025.8.3)\n",
            "Downloading pyrender-0.1.45-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyglet-2.1.8-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading freetype_py-2.5.1-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: PyOpenGL\n",
            "  Building wheel for PyOpenGL (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyOpenGL: filename=PyOpenGL-3.1.0-py3-none-any.whl size=1745193 sha256=8e06d41ef23d29f6ef8f5baa73554ebd72d1e33598eca5df8a7496e020e178bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/d0/77/e69597cdbcb72ea27345036f549a737909bcf17c39789472ce\n",
            "Successfully built PyOpenGL\n",
            "Installing collected packages: PyOpenGL, pyglet, freetype-py, pyrender\n",
            "  Attempting uninstall: PyOpenGL\n",
            "    Found existing installation: PyOpenGL 3.1.10\n",
            "    Uninstalling PyOpenGL-3.1.10:\n",
            "      Successfully uninstalled PyOpenGL-3.1.10\n",
            "Successfully installed PyOpenGL-3.1.0 freetype-py-2.5.1 pyglet-2.1.8 pyrender-0.1.45\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch torchvision tqdm einops\n",
        "!pip install -q objaverse objaverse-xl\n",
        "!pip install objaverse trimesh pyrender imageio\n",
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CBwkLia0SuI2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBwkLia0SuI2",
        "outputId": "6ec8d25e-a1b6-450c-b4ea-4bc73d1ace60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os, random, math, json, glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import tqdm\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wkqMgmxKSxgO",
      "metadata": {
        "id": "wkqMgmxKSxgO"
      },
      "outputs": [],
      "source": [
        "DATA_ROOT = \"/content/dataset_objaverse\"\n",
        "MANIFEST = \"/content/relighting_manifest.json\"\n",
        "RELIGHT_OUT = \"/content/relighting_out\"\n",
        "NERF_OUT = \"/content/nerf_out\"\n",
        "\n",
        "RELIGHT_EPOCHS = 20\n",
        "RELIGHT_BS = 2\n",
        "NERF_EPOCHS = 50\n",
        "NERF_BATCH_RAYS = 2048\n",
        "NERF_N_SAMPLES = 64\n",
        "IMAGE_SIZE = 128\n",
        "NUM_VIEWS = 8\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jymY_mkxS1bu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jymY_mkxS1bu",
        "outputId": "eb7e8551-4b93-4e2c-8812-52e6eb3b323a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA_ROOT non-empty; skipping dummy generation.\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(DATA_ROOT, exist_ok=True)\n",
        "\n",
        "if len(os.listdir(DATA_ROOT)) == 0:\n",
        "    print(\"DATA_ROOT empty — generating dummy assets...\")\n",
        "    import random\n",
        "    for a in range(8):\n",
        "        ad = os.path.join(DATA_ROOT, f\"asset_{a}\")\n",
        "        os.makedirs(os.path.join(ad, \"images\"), exist_ok=True)\n",
        "        for v in range(NUM_VIEWS):\n",
        "            img = Image.new(\"RGB\", (IMAGE_SIZE, IMAGE_SIZE),\n",
        "                            (random.randint(0,255), random.randint(0,255), random.randint(0,255)))\n",
        "            d = Image.Draw.Draw(img)\n",
        "            d.text((8, IMAGE_SIZE//2), f\"asset{a}_v{v}\", fill=(255,255,255))\n",
        "            img.save(os.path.join(ad, \"images\", f\"view_{v}.png\"))\n",
        "    print(\"Dummy assets generated.\")\n",
        "else:\n",
        "    print(\"DATA_ROOT non-empty; skipping dummy generation.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x0wkWIgPS4gC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0wkWIgPS4gC",
        "outputId": "0c960076-fd46-454d-9148-8162a96f18ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforms created or verified for each asset.\n"
          ]
        }
      ],
      "source": [
        "def make_spherical_transforms(n_views=NUM_VIEWS, radius=1.0):\n",
        "    frames = []\n",
        "    for i in range(n_views):\n",
        "        theta = 2*math.pi * i / n_views\n",
        "        cam_pos = [radius * math.sin(theta), 0.0, radius * math.cos(theta)]\n",
        "        T = np.eye(4)\n",
        "        T[:3,3] = cam_pos\n",
        "        frames.append({\n",
        "            \"file_path\": f\"images/view_{i}.png\",\n",
        "            \"transform_matrix\": T.tolist()\n",
        "        })\n",
        "    return {\"camera_angle_x\": 0.69, \"frames\": frames}\n",
        "\n",
        "for asset in sorted(os.listdir(DATA_ROOT)):\n",
        "    ad = os.path.join(DATA_ROOT, asset)\n",
        "    if not os.path.isdir(ad): continue\n",
        "    tfp = os.path.join(ad, \"transforms.json\")\n",
        "    if os.path.exists(tfp):\n",
        "        continue\n",
        "    else:\n",
        "        d = make_spherical_transforms(NUM_VIEWS)\n",
        "        with open(tfp, \"w\") as f:\n",
        "            json.dump(d, f, indent=2)\n",
        "print(\"Transforms created or verified for each asset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0C6HnvPAS7kc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C6HnvPAS7kc",
        "outputId": "cbaf88b6-792e-43df-9c22-0ccc1b6f5c43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Manifest saved to /content/relighting_manifest.json, with 15 scenes\n"
          ]
        }
      ],
      "source": [
        "import os, json\n",
        "\n",
        "DATA_ROOT = \"/content/dataset_objaverse\"\n",
        "MANIFEST = \"/content/relighting_manifest.json\"\n",
        "\n",
        "scenes = []\n",
        "for asset in sorted(os.listdir(DATA_ROOT)):\n",
        "    ad = os.path.join(DATA_ROOT, asset)\n",
        "    if not os.path.isdir(ad):\n",
        "        continue\n",
        "    images = sorted([p for p in os.listdir(ad) if p.endswith(\".png\") or p.endswith(\".jpg\")])\n",
        "    if len(images) == 0:\n",
        "        continue\n",
        "    scenes.append({\n",
        "        \"folder\": ad,\n",
        "        \"images\": images,\n",
        "        \"reference_index\": 0\n",
        "    })\n",
        "\n",
        "with open(MANIFEST, \"w\") as f:\n",
        "    json.dump({\"scenes\": scenes}, f, indent=2)\n",
        "\n",
        "print(f\"✅ Manifest saved to {MANIFEST}, with {len(scenes)} scenes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aKSCyHG_TAGY",
      "metadata": {
        "id": "aKSCyHG_TAGY"
      },
      "outputs": [],
      "source": [
        "class MultiViewRelightDataset(Dataset):\n",
        "    def __init__(self, manifest_path, image_size=IMAGE_SIZE, num_views=NUM_VIEWS, transform=None):\n",
        "        with open(manifest_path, 'r') as f:\n",
        "            manifest = json.load(f)\n",
        "        self.scenes = manifest['scenes']\n",
        "        self.image_size = image_size\n",
        "        self.num_views = num_views\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.scenes)\n",
        "    def __getitem__(self, idx):\n",
        "        scene = self.scenes[idx]\n",
        "        folder = scene['folder']\n",
        "        images = scene['images']\n",
        "        ref = scene.get('reference_index', 0)\n",
        "        others = [i for i in range(len(images)) if i != ref]\n",
        "        pick_rest = self.num_views - 1\n",
        "        picked = [ref] + random.sample(others, min(pick_rest, len(others)))\n",
        "        arrs = []\n",
        "        for i in picked:\n",
        "            img = Image.open(os.path.join(folder, images[i])).convert('RGB').resize((self.image_size,self.image_size))\n",
        "            if self.transform:\n",
        "                arrs.append(self.transform(img))\n",
        "            else:\n",
        "                arrs.append(transforms.ToTensor()(img))\n",
        "        arrs = torch.stack(arrs, dim=0)\n",
        "\n",
        "        shading_embed = torch.zeros(1)\n",
        "        return {\"images\": arrs, \"refer_idx\": 0, \"asset_folder\": folder, \"shading\": shading_embed}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5vf4y3Y6TBCS",
      "metadata": {
        "id": "5vf4y3Y6TBCS"
      },
      "outputs": [],
      "source": [
        "class UNetRelight(nn.Module):\n",
        "    def __init__(self, in_ch=3, out_ch=3, base=64):\n",
        "        super().__init__()\n",
        "        # Encoder\n",
        "        self.enc1 = nn.Sequential(nn.Conv2d(in_ch, base, 3, padding=1), nn.ReLU())\n",
        "        self.enc2 = nn.Sequential(nn.Conv2d(base, base*2, 3, padding=1), nn.ReLU())\n",
        "        self.enc3 = nn.Sequential(nn.Conv2d(base*2, base*4, 3, padding=1), nn.ReLU())\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.bottleneck = nn.Sequential(nn.Conv2d(base*4, base*8, 3, padding=1), nn.ReLU())\n",
        "        # Decoder\n",
        "        self.up3 = nn.ConvTranspose2d(base*8, base*4, 2, stride=2)\n",
        "        self.dec3 = nn.Sequential(nn.Conv2d(base*8, base*4, 3, padding=1), nn.ReLU())\n",
        "        self.up2 = nn.ConvTranspose2d(base*4, base*2, 2, stride=2)\n",
        "        self.dec2 = nn.Sequential(nn.Conv2d(base*4, base*2, 3, padding=1), nn.ReLU())\n",
        "        self.up1 = nn.ConvTranspose2d(base*2, base, 2, stride=2)\n",
        "        self.dec1 = nn.Sequential(nn.Conv2d(base*2, base, 3, padding=1), nn.ReLU())\n",
        "        self.outc = nn.Conv2d(base, out_ch, 1)\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool(e1))\n",
        "        e3 = self.enc3(self.pool(e2))\n",
        "        b = self.bottleneck(self.pool(e3))\n",
        "        u3 = self.up3(b)\n",
        "        d3 = self.dec3(torch.cat([u3, e3], dim=1))\n",
        "        u2 = self.up2(d3)\n",
        "        d2 = self.dec2(torch.cat([u2, e2], dim=1))\n",
        "        u1 = self.up1(d2)\n",
        "        d1 = self.dec1(torch.cat([u1, e1], dim=1))\n",
        "        out = torch.sigmoid(self.outc(d1))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QRQWUPsjw671",
      "metadata": {
        "id": "QRQWUPsjw671"
      },
      "outputs": [],
      "source": [
        "class RelightingModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RelightingModel, self).__init__()\n",
        "        self.enc1 = nn.Conv2d(3, 32, 3, stride=2, padding=1)\n",
        "        self.enc2 = nn.Conv2d(32, 64, 3, stride=2, padding=1)\n",
        "        self.enc3 = nn.Conv2d(64, 128, 3, stride=2, padding=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(128*16*16, 512)\n",
        "        self.fc2 = nn.Linear(512, 128*16*16)\n",
        "\n",
        "        self.dec1 = nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1)\n",
        "        self.dec2 = nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1)\n",
        "        self.dec3 = nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.enc1(x))\n",
        "        h = F.relu(self.enc2(h))\n",
        "        h = F.relu(self.enc3(h))\n",
        "\n",
        "        B, C, H, W = h.shape\n",
        "        h = h.view(B, -1)\n",
        "        h = F.relu(self.fc1(h))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        h = h.view(B, 128, H, W)\n",
        "\n",
        "        h = F.relu(self.dec1(h))\n",
        "        h = F.relu(self.dec2(h))\n",
        "        out = torch.sigmoid(self.dec3(h))\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mhyQggP6TEJo",
      "metadata": {
        "id": "mhyQggP6TEJo"
      },
      "outputs": [],
      "source": [
        "def train_relighting(manifest_path, out_dir, epochs=3, bs=1, image_size=128, num_views=8, save_interval=1):\n",
        "    ds = MultiViewRelightDataset(manifest_path, image_size=image_size, num_views=num_views)\n",
        "    dl = DataLoader(ds, batch_size=bs, shuffle=True)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = RelightingModel().to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        pbar = tqdm(dl, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "        for batch in pbar:\n",
        "            imgs = batch['images'].to(device)  # [B,V,3,H,W]\n",
        "            ref = imgs[:,0]  # نمای مرجع\n",
        "            out = model(ref)\n",
        "            loss = loss_fn(out, ref)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dl)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        save_epoch_dir = os.path.join(out_dir, f\"epoch_{epoch+1}\")\n",
        "        os.makedirs(save_epoch_dir, exist_ok=True)\n",
        "        ref_img = ref[0].detach().cpu().permute(1,2,0).numpy()\n",
        "        out_img = out[0].detach().cpu().permute(1,2,0).numpy()\n",
        "        Image.fromarray((ref_img*255).astype(\"uint8\")).save(os.path.join(save_epoch_dir, \"input.png\"))\n",
        "        Image.fromarray((out_img*255).astype(\"uint8\")).save(os.path.join(save_epoch_dir, \"relit.png\"))\n",
        "\n",
        "    torch.save(model.state_dict(), os.path.join(out_dir, 'relighting_model.pth'))\n",
        "    print(f\"✅ Training finished. Model saved to {out_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7rYv2sdRTHpi",
      "metadata": {
        "id": "7rYv2sdRTHpi"
      },
      "outputs": [],
      "source": [
        "class NeRFDataset(Dataset):\n",
        "    def __init__(self, relit_root, img_size=IMAGE_SIZE, n_rays=None):\n",
        "        self.items = []  # list of dicts: {image_path, pose, asset}\n",
        "        self.img_size = img_size\n",
        "        for asset in sorted(os.listdir(relit_root)):\n",
        "            ad = os.path.join(relit_root, asset)\n",
        "            if not os.path.isdir(ad): continue\n",
        "            imgs = sorted([f for f in os.listdir(ad) if f.endswith(\".png\") or f.endswith(\".jpg\")])\n",
        "            if len(imgs) == 0: continue\n",
        "            original_asset = os.path.join(DATA_ROOT, asset)\n",
        "            tfp = os.path.join(original_asset, \"transforms.json\")\n",
        "            poses = {}\n",
        "            if os.path.exists(tfp):\n",
        "                data = json.load(open(tfp))\n",
        "                for fr in data[\"frames\"]:\n",
        "                    poses[os.path.basename(fr[\"file_path\"])] = fr[\"transform_matrix\"]\n",
        "            for imf in imgs:\n",
        "                path = os.path.join(ad, imf)\n",
        "                pose = poses.get(imf, None)\n",
        "                self.items.append({\"path\": path, \"pose\": pose, \"asset\": asset})\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "    def __getitem__(self, idx):\n",
        "        it = self.items[idx]\n",
        "        img = Image.open(it[\"path\"]).convert(\"RGB\").resize((self.img_size,self.img_size))\n",
        "        img = transforms.ToTensor()(img)\n",
        "        pose = it[\"pose\"]\n",
        "        return {\"image\": img, \"pose\": pose, \"path\": it[\"path\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DRhFSAxZTKSk",
      "metadata": {
        "id": "DRhFSAxZTKSk"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, in_dim, num_freqs):\n",
        "        super().__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.num_freqs = num_freqs\n",
        "        self.freq_bands = 2.0 ** torch.linspace(0, num_freqs-1, num_freqs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, in_dim]\n",
        "        out = [x]\n",
        "        for freq in self.freq_bands:\n",
        "            out.append(torch.sin(freq * x))\n",
        "            out.append(torch.cos(freq * x))\n",
        "        return torch.cat(out, dim=-1)   # [B, in_dim * (2*num_freqs + 1)]\n",
        "\n",
        "\n",
        "class NeRF(nn.Module):\n",
        "    def __init__(self, D=8, W=256, in_dim_x=3, in_dim_d=3, Lx=10, Ld=4):\n",
        "        super().__init__()\n",
        "\n",
        "        # positional encoders\n",
        "        self.pe_x = PositionalEncoding(in_dim_x, Lx)\n",
        "        self.pe_d = PositionalEncoding(in_dim_d, Ld)\n",
        "\n",
        "        # encoded sizes\n",
        "        self.in_dim_x = in_dim_x * (2*Lx + 1)\n",
        "        self.in_dim_d = in_dim_d * (2*Ld + 1)\n",
        "\n",
        "        # MLP\n",
        "        layers = []\n",
        "        dim = self.in_dim_x\n",
        "        for i in range(D):\n",
        "            layers.append(nn.Linear(dim, W))\n",
        "            layers.append(nn.ReLU(True))\n",
        "            dim = W\n",
        "        self.mlp_xyz = nn.Sequential(*layers)\n",
        "\n",
        "        # σ\n",
        "        self.fc_sigma = nn.Linear(W, 1)\n",
        "\n",
        "        # orientation\n",
        "        self.fc_feat = nn.Linear(W, W)\n",
        "        self.mlp_dir = nn.Sequential(\n",
        "            nn.Linear(W + self.in_dim_d, W//2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(W//2, 3),   # RGB\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, d):\n",
        "        x_enc = self.pe_x(x)\n",
        "        d_enc = self.pe_d(d)\n",
        "\n",
        "        h = self.mlp_xyz(x_enc)\n",
        "        sigma = F.relu(self.fc_sigma(h))\n",
        "\n",
        "        feat = self.fc_feat(h)\n",
        "        h_rgb = torch.cat([feat, d_enc], dim=-1)\n",
        "        rgb = self.mlp_dir(h_rgb)\n",
        "\n",
        "        return rgb, sigma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "inWmHUa6TO_3",
      "metadata": {
        "id": "inWmHUa6TO_3"
      },
      "outputs": [],
      "source": [
        "def get_ray_directions(H, W, focal):\n",
        "    i, j = torch.meshgrid(torch.arange(W), torch.arange(H), indexing='xy')\n",
        "    i = i.t().float(); j = j.t().float()\n",
        "    dirs = torch.stack([(i - W*0.5)/focal, -(j - H*0.5)/focal, -torch.ones_like(i)], -1)  # [H,W,3]\n",
        "    return dirs\n",
        "\n",
        "def sample_points_along_rays(origins, directions, near, far, N_samples):\n",
        "    # origins, directions\n",
        "    t_vals = torch.linspace(near, far, N_samples).to(origins.device)\n",
        "    t_vals = t_vals.expand(origins.shape[0], N_samples)\n",
        "    pts = origins.unsqueeze(1) + directions.unsqueeze(1) * t_vals.unsqueeze(-1)  # [num_rays, N_samples, 3]\n",
        "    return pts, t_vals\n",
        "\n",
        "def volume_rendering(rgb, sigma, z_vals, dirs):\n",
        "    # rgb: [num_rays, N_samples, 3], sigma: [num_rays, N_samples, 1]\n",
        "    deltas = z_vals[:,1:] - z_vals[:,:-1]\n",
        "    delta_last = 1e10 * torch.ones_like(deltas[:,:1])\n",
        "    deltas = torch.cat([deltas, delta_last], dim=1)\n",
        "    alpha = 1.0 - torch.exp(-sigma.squeeze(-1) * deltas)\n",
        "    weights = alpha * torch.cumprod(torch.cat([torch.ones((alpha.shape[0],1), device=alpha.device), 1.0 - alpha + 1e-10], dim=1), dim=1)[:,:-1]\n",
        "    # weights: [num_rays, N_samples]\n",
        "    comp_rgb = (weights.unsqueeze(-1) * rgb).sum(dim=1)\n",
        "    return comp_rgb, weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5T1Jql29TQBk",
      "metadata": {
        "id": "5T1Jql29TQBk"
      },
      "outputs": [],
      "source": [
        "def load_transforms_for_asset(asset_folder):\n",
        "    tfp = os.path.join(asset_folder, \"transforms.json\")\n",
        "    if not os.path.exists(tfp):\n",
        "        return None\n",
        "    return json.load(open(tfp))\n",
        "\n",
        "def train_nerf_on_relit(relight_dir, out_dir, steps=2000, batch_rays=1024, N_samples=64, H=128, W=128):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = NeRF().to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    # rays + directions\n",
        "    rays_o = torch.rand(10000, 3)   # source of rays\n",
        "    rays_d = torch.rand(10000, 3)   # direction of rays\n",
        "    target_rgb = torch.rand(10000, 3)\n",
        "\n",
        "    rays_o, rays_d, target_rgb = rays_o.to(device), rays_d.to(device), target_rgb.to(device)\n",
        "\n",
        "    for step in range(steps):\n",
        "        idx = torch.randint(0, rays_o.shape[0], (batch_rays,))\n",
        "        ro, rd, target = rays_o[idx], rays_d[idx], target_rgb[idx]\n",
        "\n",
        "        z_vals = torch.linspace(0, 1, N_samples).to(device)\n",
        "        pts = ro.unsqueeze(1) + rd.unsqueeze(1) * z_vals.unsqueeze(0).unsqueeze(-1)  # [B,N_samples,3]\n",
        "\n",
        "        B = pts.shape[0]\n",
        "        pts_flat = pts.reshape(-1, 3)\n",
        "        dirs = rd.unsqueeze(1).expand(B, N_samples, 3).reshape(-1, 3)\n",
        "\n",
        "        rgb, sigma = model(pts_flat, dirs)\n",
        "        rgb = rgb.view(B, N_samples, 3)\n",
        "\n",
        "        pred_rgb = rgb.mean(dim=1)\n",
        "        loss = loss_fn(pred_rgb, target)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print(f\"[{step}/{steps}] loss = {loss.item():.4f}\")\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    torch.save(model.state_dict(), os.path.join(out_dir, \"nerf_model.pth\"))\n",
        "    print(\"✅ NeRF training done & saved\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6THtnp4PTTu2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6THtnp4PTTu2",
        "outputId": "4a787096-0d48-481f-f736-88e8f6f7949f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20: 100%|██████████| 8/8 [00:01<00:00,  4.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 | Loss: 0.0740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20: 100%|██████████| 8/8 [00:00<00:00, 39.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20 | Loss: 0.0779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20: 100%|██████████| 8/8 [00:00<00:00, 43.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20 | Loss: 0.0713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20: 100%|██████████| 8/8 [00:00<00:00, 43.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20 | Loss: 0.0680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20: 100%|██████████| 8/8 [00:00<00:00, 43.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20 | Loss: 0.0744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20: 100%|██████████| 8/8 [00:00<00:00, 42.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20 | Loss: 0.0768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20: 100%|██████████| 8/8 [00:00<00:00, 43.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20 | Loss: 0.0773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20: 100%|██████████| 8/8 [00:00<00:00, 44.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20 | Loss: 0.0716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20: 100%|██████████| 8/8 [00:00<00:00, 43.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20 | Loss: 0.0652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20: 100%|██████████| 8/8 [00:00<00:00, 43.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20 | Loss: 0.0614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20: 100%|██████████| 8/8 [00:00<00:00, 43.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20 | Loss: 0.0577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20: 100%|██████████| 8/8 [00:00<00:00, 42.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20 | Loss: 0.0564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20: 100%|██████████| 8/8 [00:00<00:00, 44.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20 | Loss: 0.0631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20: 100%|██████████| 8/8 [00:00<00:00, 44.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20 | Loss: 0.0591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20: 100%|██████████| 8/8 [00:00<00:00, 42.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20 | Loss: 0.0614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20: 100%|██████████| 8/8 [00:00<00:00, 43.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20 | Loss: 0.0580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20: 100%|██████████| 8/8 [00:00<00:00, 42.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20 | Loss: 0.0605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20: 100%|██████████| 8/8 [00:00<00:00, 44.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20 | Loss: 0.0544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20: 100%|██████████| 8/8 [00:00<00:00, 44.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20 | Loss: 0.0563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20: 100%|██████████| 8/8 [00:00<00:00, 44.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20 | Loss: 0.0485\n",
            "✅ Training finished. Model saved to /content/relighting_out\n",
            "Relit outputs for: epoch_1 -> ['input.png', 'relit.png']\n",
            "Relit outputs for: epoch_10 -> ['input.png', 'relit.png']\n",
            "Relit outputs for: epoch_11 -> ['input.png', 'relit.png']\n",
            "Relit outputs for: epoch_12 -> ['input.png', 'relit.png']\n",
            "Relit outputs for: epoch_13 -> ['input.png', 'relit.png']\n",
            "[0/50] loss = 0.0827\n",
            "✅ NeRF training done & saved\n",
            "Pipeline finished.\n"
          ]
        }
      ],
      "source": [
        "# 1) Relighting\n",
        "os.makedirs(RELIGHT_OUT, exist_ok=True)\n",
        "train_relighting(MANIFEST, RELIGHT_OUT, epochs=RELIGHT_EPOCHS, bs=RELIGHT_BS, image_size=IMAGE_SIZE, num_views=NUM_VIEWS)\n",
        "\n",
        "for asset in sorted(os.listdir(RELIGHT_OUT))[:5]:\n",
        "    print(\"Relit outputs for:\", asset, \"->\", os.listdir(os.path.join(RELIGHT_OUT, asset))[:5])\n",
        "\n",
        "# 2) Train NeRF روی relit images\n",
        "os.makedirs(NERF_OUT, exist_ok=True)\n",
        "train_nerf_on_relit(RELIGHT_OUT, NERF_OUT, steps=NERF_EPOCHS, batch_rays=NERF_BATCH_RAYS, N_samples=NERF_N_SAMPLES, H=IMAGE_SIZE, W=IMAGE_SIZE)\n",
        "\n",
        "print(\"Pipeline finished.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yIthfvIgniEp",
      "metadata": {
        "id": "yIthfvIgniEp"
      },
      "outputs": [],
      "source": [
        "# Test\n",
        "# Relighting\n",
        "def test_relighting(manifest_path, model_ckpt, out_dir, image_size=128, num_views=8):\n",
        "    ds = MultiViewRelightDataset(manifest_path, image_size=image_size, num_views=num_views)\n",
        "    dl = DataLoader(ds, batch_size=1, shuffle=False)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = RelightingModel().to(device)\n",
        "    model.load_state_dict(torch.load(model_ckpt, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(tqdm(dl, desc=\"relighting-test\")):\n",
        "            imgs = batch['images'].to(device)  # [1, V, 3, H, W]\n",
        "            ref = imgs[:, 0]\n",
        "            out = model(ref)\n",
        "\n",
        "            # ذخیره ورودی و خروجی برای مقایسه\n",
        "            scene_dir = os.path.join(out_dir, f\"scene_{idx}\")\n",
        "            os.makedirs(scene_dir, exist_ok=True)\n",
        "\n",
        "            ref_img = ref[0].cpu().permute(1,2,0).numpy()\n",
        "            ref_img = (ref_img*255).astype(\"uint8\")\n",
        "            Image.fromarray(ref_img).save(os.path.join(scene_dir, \"input.png\"))\n",
        "\n",
        "            out_img = out[0].cpu().permute(1,2,0).numpy()\n",
        "            out_img = (out_img*255).astype(\"uint8\")\n",
        "            Image.fromarray(out_img).save(os.path.join(scene_dir, \"relit.png\"))\n",
        "\n",
        "    print(f\"Relit test images saved to {out_dir}\")\n",
        "\n",
        "\n",
        "# NeRF\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def test_nerf(model_ckpt, out_dir, res=64, num_samples=32):\n",
        "    \"\"\"\n",
        "    تست مدل NeRF → رندر چند تصویر ساده\n",
        "    \"\"\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = NeRF().to(device)   # ← همون معماری مقاله\n",
        "    model.load_state_dict(torch.load(model_ckpt, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    test_angles = [0, 90, 180, 270]\n",
        "\n",
        "    for angle in tqdm(test_angles, desc=\"NeRF test rendering\"):\n",
        "        rays_o = torch.zeros(res*res, 3, device=device)\n",
        "        rays_d = torch.randn(res*res, 3, device=device)\n",
        "\n",
        "        t_vals = torch.linspace(0., 1., steps=num_samples, device=device)\n",
        "        pts = rays_o.unsqueeze(1) + rays_d.unsqueeze(1) * t_vals.view(1, -1, 1)\n",
        "\n",
        "        pts_flat = pts.reshape(-1, 3)\n",
        "        dirs_flat = rays_d.unsqueeze(1).expand(-1, num_samples, -1).reshape(-1, 3)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            rgb, sigma = model(pts_flat, dirs_flat)   # ✅ اینجا هر دو خروجی رو بگیر\n",
        "            rgb = rgb.view(rays_o.shape[0], num_samples, 3)\n",
        "\n",
        "            rgb_final = rgb.mean(dim=1).clamp(0,1)\n",
        "\n",
        "        img = (rgb_final.view(res, res, 3).cpu().numpy() * 255).astype(np.uint8)\n",
        "        Image.fromarray(img).save(os.path.join(out_dir, f\"render_angle{angle}.png\"))\n",
        "\n",
        "    print(f\"تست NeRF تمام شد → تصاویر در {out_dir} ذخیره شدند\")\n",
        "\n",
        "\n",
        "\n",
        "# MSE و PSNR\n",
        "def psnr(mse_loss):\n",
        "    return 10 * math.log10(1.0 / mse_loss)\n",
        "\n",
        "def evaluate_relighting(manifest_path, model_ckpt, image_size=128, num_samples=10):\n",
        "    ds = MultiViewRelightDataset(manifest_path, image_size=image_size)\n",
        "    dl = DataLoader(ds, batch_size=1, shuffle=True)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = RelightingModel().to(device)\n",
        "    model.load_state_dict(torch.load(model_ckpt))\n",
        "    model.eval()\n",
        "\n",
        "    loss_fn = nn.MSELoss()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(dl):\n",
        "            if i >= num_samples: break\n",
        "            imgs = batch['images'].to(device)\n",
        "            ref = imgs[:,0]\n",
        "            out = model(ref)\n",
        "            loss = loss_fn(out, ref)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / num_samples\n",
        "    print(f\"📊 Relighting Eval → MSE: {avg_loss:.6f}, PSNR: {psnr(avg_loss):.2f} dB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZMxdKhR1niyY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMxdKhR1niyY",
        "outputId": "283ec438-2c4c-4630-d490-983267d68926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "relighting-test: 100%|██████████| 15/15 [00:00<00:00, 73.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relit test images saved to /content/test_relighting\n",
            "📊 Relighting Eval → MSE: 0.050889, PSNR: 12.93 dB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "NeRF test rendering: 100%|██████████| 4/4 [00:00<00:00, 13.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تست NeRF تمام شد → تصاویر در /content/test_nerf ذخیره شدند\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test_relighting(MANIFEST, os.path.join(RELIGHT_OUT, \"relighting_model.pth\"), \"/content/test_relighting\")\n",
        "evaluate_relighting(MANIFEST, os.path.join(RELIGHT_OUT, \"relighting_model.pth\"))\n",
        "\n",
        "test_nerf(os.path.join(NERF_OUT, \"nerf_model.pth\"), \"/content/test_nerf\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vCdhnE9t2g4m",
      "metadata": {
        "id": "vCdhnE9t2g4m"
      },
      "source": [
        "### Advanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "878982f5-f40c-46ee-cc6f-3ebb7655c8cb",
        "id": "BskEWotj3uXv"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting diffusers==0.21.4\n",
            "  Downloading diffusers-0.21.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting accelerate==0.25.0\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers==0.21.4) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers==0.21.4) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.21.4) (0.34.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from diffusers==0.21.4) (8.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers==0.21.4) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.21.4) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers==0.21.4) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.21.4) (0.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.21.4) (2025.3.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.21.4) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.21.4) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.21.4) (1.1.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.4.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->diffusers==0.21.4) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.21.4) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.21.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.21.4) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.21.4) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.25.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0) (3.0.2)\n",
            "Downloading diffusers-0.21.4-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diffusers, accelerate\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.35.1\n",
            "    Uninstalling diffusers-0.35.1:\n",
            "      Successfully uninstalled diffusers-0.35.1\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.10.1\n",
            "    Uninstalling accelerate-1.10.1:\n",
            "      Successfully uninstalled accelerate-1.10.1\n",
            "Successfully installed accelerate-0.25.0 diffusers-0.21.4\n",
            "Collecting nerfacc\n",
            "  Downloading nerfacc-0.5.3-py3-none-any.whl.metadata (915 bytes)\n",
            "Collecting trimesh\n",
            "  Downloading trimesh-4.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Collecting objaverse==0.1.7\n",
            "  Downloading objaverse-0.1.7-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: imageio[ffmpeg] in /usr/local/lib/python3.12/dist-packages (2.37.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from objaverse==0.1.7) (2.32.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from objaverse==0.1.7) (2.2.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from objaverse==0.1.7) (18.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from objaverse==0.1.7) (4.67.1)\n",
            "Collecting loguru (from objaverse==0.1.7)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: fsspec>=2022.11.0 in /usr/local/lib/python3.12/dist-packages (from objaverse==0.1.7) (2025.3.0)\n",
            "Collecting gputil==1.4.0 (from objaverse==0.1.7)\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: rich>=12 in /usr/local/lib/python3.12/dist-packages (from nerfacc) (13.9.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from nerfacc) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.12/dist-packages (from trimesh) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio[ffmpeg]) (11.3.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.12/dist-packages (from imageio[ffmpeg]) (0.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from imageio[ffmpeg]) (5.9.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12->nerfacc) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12->nerfacc) (2.19.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->objaverse==0.1.7) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->objaverse==0.1.7) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->objaverse==0.1.7) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->objaverse==0.1.7) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->objaverse==0.1.7) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->objaverse==0.1.7) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->nerfacc) (3.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12->nerfacc) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->nerfacc) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->nerfacc) (3.0.2)\n",
            "Downloading objaverse-0.1.7-py3-none-any.whl (32 kB)\n",
            "Downloading nerfacc-0.5.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trimesh-4.8.1-py3-none-any.whl (728 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=049c0166439c01e326a1a8454af9f758895d1a59df06e0e9f3598eb0918dad83\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a8/b7/d8a067c31a74de9ca252bbe53dea5f896faabd25d55f541037\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil, trimesh, loguru, objaverse, nerfacc\n",
            "Successfully installed gputil-1.4.0 loguru-0.7.3 nerfacc-0.5.3 objaverse-0.1.7 trimesh-4.8.1\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (4.55.4)\n",
            "Collecting transformers<5.0.0,>=4.41.0\n",
            "  Downloading transformers-4.56.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (2.32.4)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0)\n",
            "  Downloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.41.0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.41.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.41.0) (1.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.41.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.41.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.41.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.41.0) (2025.8.3)\n",
            "Downloading transformers-4.56.0-py3-none-any.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.4\n",
            "    Uninstalling tokenizers-0.21.4:\n",
            "      Successfully uninstalled tokenizers-0.21.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.55.4\n",
            "    Uninstalling transformers-4.55.4:\n",
            "      Successfully uninstalled transformers-4.55.4\n",
            "Successfully installed tokenizers-0.22.0 transformers-4.56.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-09-02 20:35:41.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.github\u001b[0m:\u001b[36m_get_annotations\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mDownloading https://huggingface.co/datasets/allenai/objaverse-xl/resolve/main/github/github.parquet to objaverse_data/github/github.parquet\u001b[0m\n",
            "\u001b[32m2025-09-02 20:36:12.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36mget_annotations\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mDownloading https://huggingface.co/datasets/allenai/objaverse-xl/resolve/main/thingiverse/thingiverse.parquet to objaverse_data/thingiverse/thingiverse.parquet\u001b[0m\n",
            "\u001b[32m2025-09-02 20:36:27.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.smithsonian\u001b[0m:\u001b[36mget_annotations\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mDownloading https://huggingface.co/datasets/allenai/objaverse-xl/resolve/main/smithsonian/smithsonian.parquet to objaverse_data/smithsonian/smithsonian.parquet\u001b[0m\n",
            "\u001b[32m2025-09-02 20:36:28.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.sketchfab\u001b[0m:\u001b[36m_get_annotations\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mDownloading https://huggingface.co/datasets/allenai/objaverse-xl/resolve/main/sketchfab/sketchfab.parquet to objaverse_data/sketchfab/sketchfab.parquet\u001b[0m\n",
            "\u001b[32m2025-09-02 20:36:34.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36mdownload_objects\u001b[0m:\u001b[36m370\u001b[0m - \u001b[1mFound 0 Thingiverse objects downloaded\u001b[0m\n",
            "\u001b[32m2025-09-02 20:36:34.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36mdownload_objects\u001b[0m:\u001b[36m376\u001b[0m - \u001b[1mDownloading 7 Thingiverse objects with processes=4\u001b[0m\n",
            "Downloading Thingiverse Objects:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[32m2025-09-02 20:36:50.081\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36m_download_item\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mThingiverse file ID 8615832 could not get response from https://www.thingiverse.com/download:8615832\u001b[0m\n",
            "\u001b[32m2025-09-02 20:36:50.082\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36m_download_item\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mThingiverse file ID 13150470 could not get response from https://www.thingiverse.com/download:13150470\u001b[0m\n",
            "Downloading Thingiverse Objects:  14%|█▍        | 1/7 [00:15<01:31, 15.20s/it]\u001b[32m2025-09-02 20:36:50.085\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36m_download_item\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mThingiverse file ID 9489375 could not get response from https://www.thingiverse.com/download:9489375\u001b[0m\n",
            "\u001b[32m2025-09-02 20:36:50.103\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36m_download_item\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mThingiverse file ID 11589677 could not get response from https://www.thingiverse.com/download:11589677\u001b[0m\n",
            "\u001b[32m2025-09-02 20:37:05.270\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36m_download_item\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mThingiverse file ID 674402 could not get response from https://www.thingiverse.com/download:674402\u001b[0m\n",
            "Downloading Thingiverse Objects:  71%|███████▏  | 5/7 [00:30<00:10,  5.49s/it]\u001b[32m2025-09-02 20:37:05.293\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36m_download_item\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mThingiverse file ID 1535139 could not get response from https://www.thingiverse.com/download:1535139\u001b[0m\n",
            "\u001b[32m2025-09-02 20:37:05.313\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mobjaverse.xl.thingiverse\u001b[0m:\u001b[36m_download_item\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mThingiverse file ID 3634667 could not get response from https://www.thingiverse.com/download:3634667\u001b[0m\n",
            "Downloading Thingiverse Objects: 100%|██████████| 7/7 [00:30<00:00,  4.35s/it]\n",
            "\u001b[32m2025-09-02 20:37:07.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.sketchfab\u001b[0m:\u001b[36mdownload_objects\u001b[0m:\u001b[36m508\u001b[0m - \u001b[1mFound 0 objects already downloaded\u001b[0m\n",
            "\u001b[32m2025-09-02 20:37:07.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.sketchfab\u001b[0m:\u001b[36mdownload_objects\u001b[0m:\u001b[36m529\u001b[0m - \u001b[1mDownloading 1 new objects across 4 processes\u001b[0m\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n",
            "\u001b[32m2025-09-02 20:37:10.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.github\u001b[0m:\u001b[36mdownload_objects\u001b[0m:\u001b[36m602\u001b[0m - \u001b[1mProvided 7 repoIds with 7 objects to process.\u001b[0m\n",
            "\u001b[32m2025-09-02 20:37:10.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mobjaverse.xl.github\u001b[0m:\u001b[36mdownload_objects\u001b[0m:\u001b[36m614\u001b[0m - \u001b[1mFound 7 repoIds not yet downloaded. Downloading now...\u001b[0m\n",
            "Grouping objects by repository: 100%|██████████| 7/7 [00:00<00:00, 408.07it/s]\n",
            "Downloading repositories:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[32m2025-09-02 20:37:11.439\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mobjaverse.xl.github\u001b[0m:\u001b[36m_run_command_with_check\u001b[0m:\u001b[36m172\u001b[0m - \u001b[31m\u001b[1mError:\u001b[0m\n",
            "\u001b[32m2025-09-02 20:37:11.443\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mobjaverse.xl.github\u001b[0m:\u001b[36m_run_command_with_check\u001b[0m:\u001b[36m173\u001b[0m - \u001b[31m\u001b[1mNone\u001b[0m\n",
            "\u001b[32m2025-09-02 20:37:11.446\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mobjaverse.xl.github\u001b[0m:\u001b[36m_run_command_with_check\u001b[0m:\u001b[36m174\u001b[0m - \u001b[31m\u001b[1mNone\u001b[0m\n",
            "\u001b[32m2025-09-02 20:37:11.448\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mobjaverse.xl.github\u001b[0m:\u001b[36m_process_repo\u001b[0m:\u001b[36m217\u001b[0m - \u001b[31m\u001b[1mCould not clone sarettak/3DCityReconstructionFromOSM\u001b[0m\n",
            "Handling 3D object files: 100%|██████████| 1/1 [00:00<00:00, 62.40it/s]\n",
            "Handling 3D object files: 100%|██████████| 455/455 [00:01<00:00, 276.69it/s]\n",
            "Handling 3D object files: 100%|██████████| 740/740 [00:03<00:00, 192.44it/s]\n",
            "Handling 3D object files: 100%|██████████| 2798/2798 [00:10<00:00, 275.80it/s]\n",
            "Handling 3D object files: 100%|██████████| 563/563 [00:01<00:00, 321.21it/s]\n",
            "Handling 3D object files: 100%|██████████| 465151/465151 [03:16<00:00, 2366.28it/s]\n",
            "Downloading repositories: 100%|██████████| 7/7 [08:06<00:00, 69.52s/it] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 1 assets.\n",
            "Generated dummy 8 views for each of 15 assets\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install diffusers==0.21.4 accelerate==0.25.0\n",
        "!pip install nerfacc trimesh imageio[ffmpeg] matplotlib objaverse==0.1.7\n",
        "!pip install --upgrade \"transformers>=4.41.0,<5.0.0\"\n",
        "\n",
        "import objaverse.xl as oxl\n",
        "import objaverse\n",
        "import random, os\n",
        "\n",
        "# پوشه‌ی ذخیره‌سازی فایل‌ها\n",
        "save_dir = \"objaverse_data\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# تعداد پردازش‌های موازی (اختیاری)\n",
        "num_procs = 4\n",
        "\n",
        "# 1. بارگذاری داده‌های متادیتا (Annotations) به شکل DataFrame\n",
        "annotations = oxl.get_annotations(download_dir=save_dir)\n",
        "\n",
        "# 2. نمونه‌گیری تصادفی چند آبجکت\n",
        "sample = annotations.sample(15).reset_index(drop=True)\n",
        "\n",
        "# 3. دانلود از طریق XL API به همراه مسیر ذخیره‌سازی\n",
        "objects = oxl.download_objects(\n",
        "    objects=sample,\n",
        "    download_dir=save_dir,\n",
        "    processes=num_procs\n",
        ")\n",
        "\n",
        "print(\"Downloaded\", len(objects), \"assets.\")\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "out_root = \"dataset_objaverse\"\n",
        "os.makedirs(out_root, exist_ok=True)\n",
        "\n",
        "uids = list(objaverse.load_uids())\n",
        "sample_uids = random.sample(uids, 15)  # take 15 assets\n",
        "\n",
        "for idx, uid in enumerate(sample_uids):\n",
        "    asset_dir = os.path.join(out_root, f\"asset_{idx}\")\n",
        "    os.makedirs(asset_dir, exist_ok=True)\n",
        "    for view in range(8):\n",
        "        img = Image.new(\"RGB\", (128,128), (random.randint(0,255), random.randint(0,255), random.randint(0,255)))\n",
        "        d = ImageDraw.Draw(img)\n",
        "        d.text((10,60), f\"{uid[:6]} v{view}\", fill=(255,255,255))\n",
        "        img.save(os.path.join(asset_dir, f\"view_{view}.png\"))\n",
        "print(\"Generated dummy 8 views for each of 15 assets\")"
      ],
      "id": "BskEWotj3uXv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW3XPwh23uXv"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision tqdm einops\n",
        "\n",
        "!pip install -q objaverse objaverse-xl"
      ],
      "id": "NW3XPwh23uXv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900f6eaa-45d0-4b59-9966-c0b516b39e55",
        "id": "HNKAwFqa3uXw"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os, random, math, json, glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import tqdm\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ],
      "id": "HNKAwFqa3uXw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgOlTCKR3uXw"
      },
      "outputs": [],
      "source": [
        "DATA_ROOT = \"/content/dataset_objaverse\"   # <-- مسیر دیتاست (هر asset یک فولدر شامل images/)\n",
        "MANIFEST = \"/content/relighting_manifest.json\"\n",
        "RELIGHT_OUT = \"/content/relighting_out\"\n",
        "NERF_OUT = \"/content/nerf_out\"\n",
        "\n",
        "\n",
        "RELIGHT_EPOCHS = 20\n",
        "RELIGHT_BS = 2\n",
        "NERF_EPOCHS = 50\n",
        "NERF_BATCH_RAYS = 2048\n",
        "NERF_N_SAMPLES = 64\n",
        "IMAGE_SIZE = 128\n",
        "NUM_VIEWS = 8\n",
        "random.seed(42)"
      ],
      "id": "wgOlTCKR3uXw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1366f4a-2f31-423e-e2b8-936e675af7ac",
        "id": "xluaarnd3uXw"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA_ROOT non-empty; skipping dummy generation.\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(DATA_ROOT, exist_ok=True)\n",
        "\n",
        "if len(os.listdir(DATA_ROOT)) == 0:\n",
        "    print(\"DATA_ROOT empty — generating dummy assets...\")\n",
        "    import random\n",
        "    for a in range(8):\n",
        "        ad = os.path.join(DATA_ROOT, f\"asset_{a}\")\n",
        "        os.makedirs(os.path.join(ad, \"images\"), exist_ok=True)\n",
        "        for v in range(NUM_VIEWS):\n",
        "            img = Image.new(\"RGB\", (IMAGE_SIZE, IMAGE_SIZE),\n",
        "                            (random.randint(0,255), random.randint(0,255), random.randint(0,255)))\n",
        "            d = Image.Draw.Draw(img)\n",
        "            d.text((8, IMAGE_SIZE//2), f\"asset{a}_v{v}\", fill=(255,255,255))\n",
        "            img.save(os.path.join(ad, \"images\", f\"view_{v}.png\"))\n",
        "    print(\"Dummy assets generated.\")\n",
        "else:\n",
        "    print(\"DATA_ROOT non-empty; skipping dummy generation.\")"
      ],
      "id": "xluaarnd3uXw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a76147-3223-49d4-e9cc-22624dedccd1",
        "id": "nvSx63Vk3uXw"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforms created or verified for each asset.\n"
          ]
        }
      ],
      "source": [
        "def make_spherical_transforms(n_views=NUM_VIEWS, radius=1.0):\n",
        "    frames = []\n",
        "    for i in range(n_views):\n",
        "        theta = 2*math.pi * i / n_views\n",
        "        cam_pos = [radius * math.sin(theta), 0.0, radius * math.cos(theta)]\n",
        "        T = np.eye(4)\n",
        "        T[:3,3] = cam_pos\n",
        "        frames.append({\n",
        "            \"file_path\": f\"images/view_{i}.png\",\n",
        "            \"transform_matrix\": T.tolist()\n",
        "        })\n",
        "    return {\"camera_angle_x\": 0.69, \"frames\": frames}\n",
        "\n",
        "for asset in sorted(os.listdir(DATA_ROOT)):\n",
        "    ad = os.path.join(DATA_ROOT, asset)\n",
        "    if not os.path.isdir(ad): continue\n",
        "    tfp = os.path.join(ad, \"transforms.json\")\n",
        "    if os.path.exists(tfp):\n",
        "        continue\n",
        "    else:\n",
        "        d = make_spherical_transforms(NUM_VIEWS)\n",
        "        with open(tfp, \"w\") as f:\n",
        "            json.dump(d, f, indent=2)\n",
        "print(\"Transforms created or verified for each asset.\")"
      ],
      "id": "nvSx63Vk3uXw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb63193-9963-4d83-cc22-05da1f082e85",
        "id": "Hh1sjwDt3uXx"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Manifest saved to /content/relighting_manifest.json, with 15 scenes\n"
          ]
        }
      ],
      "source": [
        "DATA_ROOT = \"/content/dataset_objaverse\"   # مسیر دیتاست ساختگی\n",
        "MANIFEST = \"/content/relighting_manifest.json\"\n",
        "\n",
        "scenes = []\n",
        "for asset in sorted(os.listdir(DATA_ROOT)):\n",
        "    ad = os.path.join(DATA_ROOT, asset)\n",
        "    if not os.path.isdir(ad):\n",
        "        continue\n",
        "\n",
        "    images = sorted([p for p in os.listdir(ad) if p.endswith(\".png\") or p.endswith(\".jpg\")])\n",
        "    if len(images) == 0:\n",
        "        continue\n",
        "    scenes.append({\n",
        "        \"folder\": ad,\n",
        "        \"images\": images,\n",
        "        \"reference_index\": 0\n",
        "    })\n",
        "\n",
        "with open(MANIFEST, \"w\") as f:\n",
        "    json.dump({\"scenes\": scenes}, f, indent=2)\n",
        "\n",
        "print(f\"Manifest saved to {MANIFEST}, with {len(scenes)} scenes\")\n"
      ],
      "id": "Hh1sjwDt3uXx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPypVBif3uXx"
      },
      "outputs": [],
      "source": [
        "class MultiViewRelightDataset(Dataset):\n",
        "    def __init__(self, manifest_path, image_size=IMAGE_SIZE, num_views=NUM_VIEWS, transform=None):\n",
        "        with open(manifest_path, 'r') as f:\n",
        "            manifest = json.load(f)\n",
        "        self.scenes = manifest['scenes']\n",
        "        self.image_size = image_size\n",
        "        self.num_views = num_views\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.scenes)\n",
        "    def __getitem__(self, idx):\n",
        "        scene = self.scenes[idx]\n",
        "        folder = scene['folder']\n",
        "        images = scene['images']\n",
        "        ref = scene.get('reference_index', 0)\n",
        "        others = [i for i in range(len(images)) if i != ref]\n",
        "        pick_rest = self.num_views - 1\n",
        "        picked = [ref] + random.sample(others, min(pick_rest, len(others)))\n",
        "        arrs = []\n",
        "        for i in picked:\n",
        "            img = Image.open(os.path.join(folder, images[i])).convert('RGB').resize((self.image_size,self.image_size))\n",
        "            if self.transform:\n",
        "                arrs.append(self.transform(img))\n",
        "            else:\n",
        "                arrs.append(transforms.ToTensor()(img))\n",
        "        arrs = torch.stack(arrs, dim=0)  # [num_views, C, H, W]\n",
        "        shading_embed = torch.zeros(1)\n",
        "        return {\"images\": arrs, \"refer_idx\": 0, \"asset_folder\": folder, \"shading\": shading_embed}"
      ],
      "id": "hPypVBif3uXx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwwqO1F43uXx"
      },
      "outputs": [],
      "source": [
        "# ResBlock\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, downsample=False):\n",
        "        super().__init__()\n",
        "        self.downsample = downsample\n",
        "        mid_ch = out_ch\n",
        "        self.conv1 = nn.Conv2d(in_ch, mid_ch, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(mid_ch)\n",
        "        self.conv2 = nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
        "        if in_ch != out_ch or downsample:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=False),\n",
        "                nn.BatchNorm2d(out_ch)\n",
        "            )\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "        self.act = nn.ReLU(inplace=True)\n",
        "        self.pool = nn.MaxPool2d(2) if downsample else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.act(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        sc = self.shortcut(x)\n",
        "        out = self.act(out + sc)\n",
        "        out = self.pool(out)\n",
        "        return out\n",
        "\n",
        "# Attention Fusion\n",
        "class ViewFusion(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.project = nn.Conv2d(in_ch, out_ch, kernel_size=1)\n",
        "        self.att_conv = nn.Conv2d(out_ch, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, view_feats):\n",
        "        stacked = torch.stack(view_feats, dim=1)  # [B, V, C, H, W]\n",
        "        B,V,C,H,W = stacked.shape\n",
        "        merged = stacked.view(B*V, C, H, W)\n",
        "        proj = self.project(merged)  # [B*V, out_ch, H, W]\n",
        "        proj = proj.view(B, V, -1, H, W)  # [B,V,out_ch,H,W]\n",
        "        att_logits = self.att_conv(proj.view(B*V, -1, H, W)).view(B, V, H, W)  # [B,V,H,W]\n",
        "        att = torch.softmax(att_logits.mean(dim=[2,3]), dim=1)  # [B,V]\n",
        "        att = att.view(B, V, 1, 1, 1)\n",
        "        fused = (proj * att).sum(dim=1)  # [B, out_ch, H, W]\n",
        "        return fused\n",
        "\n",
        "# ResUNetRelight with multi-view fusion\n",
        "class ResUNetRelight(nn.Module):\n",
        "    def __init__(self, in_ch=3, base=64, num_views=NUM_VIEWS):\n",
        "        super().__init__()\n",
        "        self.num_views = num_views\n",
        "        self.view_shallow = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, base, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(base, base, 3, padding=1), nn.ReLU()\n",
        "        )\n",
        "        # fusion\n",
        "        self.fusion = ViewFusion(base, base)\n",
        "        # encoder residual blocks\n",
        "        self.enc1 = ResBlock(base, base, downsample=False)     # out: base\n",
        "        self.enc2 = ResBlock(base, base*2, downsample=True)    # out: base*2\n",
        "        self.enc3 = ResBlock(base*2, base*4, downsample=True)  # out: base*4\n",
        "        self.enc4 = ResBlock(base*4, base*8, downsample=True)  # out: base*8\n",
        "        # bottleneck\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(base*8, base*8, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(base*8, base*8, 3, padding=1), nn.ReLU()\n",
        "        )\n",
        "        # decoder (upsample + skip)\n",
        "        self.up4 = nn.ConvTranspose2d(base*8, base*4, 2, stride=2)\n",
        "        self.dec4 = nn.Sequential(nn.Conv2d(base*8, base*4, 3, padding=1), nn.ReLU())\n",
        "        self.up3 = nn.ConvTranspose2d(base*4, base*2, 2, stride=2)\n",
        "        self.dec3 = nn.Sequential(nn.Conv2d(base*4, base*2, 3, padding=1), nn.ReLU())\n",
        "        self.up2 = nn.ConvTranspose2d(base*2, base, 2, stride=2)\n",
        "        self.dec2 = nn.Sequential(nn.Conv2d(base*2, base, 3, padding=1), nn.ReLU())\n",
        "        self.outc = nn.Conv2d(base, 3, 1)\n",
        "\n",
        "    def forward(self, views):  # views: [B, V, C, H, W]\n",
        "        B,V,C,H,W = views.shape\n",
        "        view_feats = []\n",
        "        for v in range(V):\n",
        "            x = views[:,v]  # [B,C,H,W]\n",
        "            x = self.view_shallow(x)\n",
        "            view_feats.append(x)\n",
        "        fused = self.fusion(view_feats)  # [B, base, H, W]\n",
        "        e1 = self.enc1(fused)\n",
        "        e2 = self.enc2(e1)\n",
        "        e3 = self.enc3(e2)\n",
        "        e4 = self.enc4(e3)\n",
        "        b = self.bottleneck(e4)\n",
        "        u4 = self.up4(b)\n",
        "        d4 = self.dec4(torch.cat([u4, e4], dim=1))\n",
        "        u3 = self.up3(d4)\n",
        "        d3 = self.dec3(torch.cat([u3, e3], dim=1))\n",
        "        u2 = self.up2(d3)\n",
        "        d2 = self.dec2(torch.cat([u2, e2], dim=1))\n",
        "        out = torch.sigmoid(self.outc(d2))\n",
        "        return out\n"
      ],
      "id": "OwwqO1F43uXx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pex6vdjD3uXx"
      },
      "outputs": [],
      "source": [
        "class RelightingModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RelightingModel, self).__init__()\n",
        "        self.enc1 = nn.Conv2d(3, 32, 3, stride=2, padding=1)\n",
        "        self.enc2 = nn.Conv2d(32, 64, 3, stride=2, padding=1)\n",
        "        self.enc3 = nn.Conv2d(64, 128, 3, stride=2, padding=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(128*16*16, 512)\n",
        "        self.fc2 = nn.Linear(512, 128*16*16)\n",
        "\n",
        "        self.dec1 = nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1)\n",
        "        self.dec2 = nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1)\n",
        "        self.dec3 = nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.enc1(x))   # [B,32,H/2,W/2]\n",
        "        h = F.relu(self.enc2(h))   # [B,64,H/4,W/4]\n",
        "        h = F.relu(self.enc3(h))   # [B,128,H/8,W/8]\n",
        "\n",
        "        B, C, H, W = h.shape\n",
        "        h = h.view(B, -1)\n",
        "        h = F.relu(self.fc1(h))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        h = h.view(B, 128, H, W)\n",
        "\n",
        "        h = F.relu(self.dec1(h))\n",
        "        h = F.relu(self.dec2(h))\n",
        "        out = torch.sigmoid(self.dec3(h))\n",
        "        return out\n"
      ],
      "id": "pex6vdjD3uXx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Vb0ryjs3uXy"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def train_relighting(manifest_path, out_dir, epochs=3, bs=1, image_size=128, num_views=8, save_interval=1):\n",
        "    ds = MultiViewRelightDataset(manifest_path, image_size=image_size, num_views=num_views)\n",
        "    dl = DataLoader(ds, batch_size=bs, shuffle=True)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = RelightingModel().to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        pbar = tqdm(dl, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "        for batch in pbar:\n",
        "            imgs = batch['images'].to(device)  # [B,V,3,H,W]\n",
        "            ref = model(imgs)\n",
        "            out = model(ref)\n",
        "            loss = loss_fn(out, ref)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dl)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        save_epoch_dir = os.path.join(out_dir, f\"epoch_{epoch+1}\")\n",
        "        os.makedirs(save_epoch_dir, exist_ok=True)\n",
        "        ref_img = ref[0].detach().cpu().permute(1,2,0).numpy()\n",
        "        out_img = out[0].detach().cpu().permute(1,2,0).numpy()\n",
        "        Image.fromarray((ref_img*255).astype(\"uint8\")).save(os.path.join(save_epoch_dir, \"input.png\"))\n",
        "        Image.fromarray((out_img*255).astype(\"uint8\")).save(os.path.join(save_epoch_dir, \"relit.png\"))\n",
        "\n",
        "    torch.save(model.state_dict(), os.path.join(out_dir, 'relighting_model.pth'))\n",
        "    print(f\"Training finished. Model saved to {out_dir}\")\n"
      ],
      "id": "1Vb0ryjs3uXy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0IIl7tQ3uXy"
      },
      "outputs": [],
      "source": [
        "class NeRFDataset(Dataset):\n",
        "    def __init__(self, relit_root, img_size=IMAGE_SIZE, n_rays=None):\n",
        "        self.items = []  # list of dicts: {image_path, pose, asset}\n",
        "        self.img_size = img_size\n",
        "        for asset in sorted(os.listdir(relit_root)):\n",
        "            ad = os.path.join(relit_root, asset)\n",
        "            if not os.path.isdir(ad): continue\n",
        "            # images\n",
        "            imgs = sorted([f for f in os.listdir(ad) if f.endswith(\".png\") or f.endswith(\".jpg\")])\n",
        "            if len(imgs) == 0: continue\n",
        "            # try to find transforms.json in original DATA_ROOT\n",
        "            original_asset = os.path.join(DATA_ROOT, asset)  # our naming convention\n",
        "            tfp = os.path.join(original_asset, \"transforms.json\")\n",
        "            poses = {}\n",
        "            if os.path.exists(tfp):\n",
        "                data = json.load(open(tfp))\n",
        "                for fr in data[\"frames\"]:\n",
        "                    poses[os.path.basename(fr[\"file_path\"])] = fr[\"transform_matrix\"]\n",
        "            for imf in imgs:\n",
        "                path = os.path.join(ad, imf)\n",
        "                pose = poses.get(imf, None)\n",
        "                self.items.append({\"path\": path, \"pose\": pose, \"asset\": asset})\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "    def __getitem__(self, idx):\n",
        "        it = self.items[idx]\n",
        "        img = Image.open(it[\"path\"]).convert(\"RGB\").resize((self.img_size,self.img_size))\n",
        "        img = transforms.ToTensor()(img)\n",
        "        pose = it[\"pose\"]  # may be None\n",
        "        return {\"image\": img, \"pose\": pose, \"path\": it[\"path\"]}"
      ],
      "id": "Q0IIl7tQ3uXy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d5JBpUv3uXy"
      },
      "outputs": [],
      "source": [
        "# positional encoding helper\n",
        "class PosEncoding(nn.Module):\n",
        "    def __init__(self, num_freqs):\n",
        "        super().__init__()\n",
        "        self.num_freqs = num_freqs\n",
        "        self.freq_bands = 2.0 ** torch.arange(0, num_freqs).float()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [..., D]\n",
        "        out = [x]\n",
        "        for freq in self.freq_bands:\n",
        "            out.append(torch.sin(x * freq * math.pi))\n",
        "            out.append(torch.cos(x * freq * math.pi))\n",
        "        return torch.cat(out, dim=-1)\n",
        "\n",
        "# NeRF MLP block (shared)\n",
        "def mlp_block(in_ch, out_ch):\n",
        "    return nn.Sequential(nn.Linear(in_ch, out_ch), nn.ReLU(inplace=True))\n",
        "\n",
        "# Full NeRF MLP (coarse or fine)\n",
        "class NeRF_MLP(nn.Module):\n",
        "    def __init__(self, D=8, W=256, input_ch=63, input_ch_dir=27, skips=[4], use_viewdirs=True):\n",
        "        super().__init__()\n",
        "        self.D = D; self.W = W; self.skips = skips; self.use_viewdirs = use_viewdirs\n",
        "        self.pts_linears = nn.ModuleList()\n",
        "        for i in range(D):\n",
        "            if i == 0:\n",
        "                self.pts_linears.append(nn.Linear(input_ch, W))\n",
        "            elif i in skips:\n",
        "                self.pts_linears.append(nn.Linear(W + input_ch, W))\n",
        "            else:\n",
        "                self.pts_linears.append(nn.Linear(W, W))\n",
        "        # feature -> sigma + feature\n",
        "        self.sigma_layer = nn.Linear(W, 1)\n",
        "        self.feature_layer = nn.Linear(W, W)\n",
        "        # view-dependent rgb head\n",
        "        if use_viewdirs:\n",
        "            self.rgb_layer = nn.Sequential(nn.Linear(W + input_ch_dir, W//2), nn.ReLU(), nn.Linear(W//2, 3))\n",
        "        else:\n",
        "            self.rgb_layer = nn.Linear(W, 3)\n",
        "\n",
        "    def forward(self, x, viewdirs=None):\n",
        "        h = x\n",
        "        for i, l in enumerate(self.pts_linears):\n",
        "            if i in self.skips and i != 0:\n",
        "                h = torch.cat([h, x], dim=-1)\n",
        "            h = F.relu(l(h))\n",
        "        sigma = F.relu(self.sigma_layer(h))\n",
        "        feat = self.feature_layer(h)\n",
        "        if self.use_viewdirs and viewdirs is not None:\n",
        "            h2 = torch.cat([feat, viewdirs], dim=-1)\n",
        "            rgb = torch.sigmoid(self.rgb_layer(h2))\n",
        "        else:\n",
        "            rgb = torch.sigmoid(self.rgb_layer(feat))\n",
        "        return rgb, sigma\n",
        "\n",
        "# sampling helpers (stratified + importance)\n",
        "def sample_stratified(n_rays, n_samples, near, far, device):\n",
        "    t_vals = torch.linspace(0.0, 1.0, n_samples, device=device)\n",
        "    mids = 0.5 * (t_vals[:-1] + t_vals[1:])\n",
        "    upper = torch.cat([mids, t_vals[-1].unsqueeze(0)], 0)\n",
        "    lower = torch.cat([t_vals[0].unsqueeze(0), mids], 0)\n",
        "    t_rand = torch.rand((n_rays, n_samples), device=device)\n",
        "    t_vals = lower.unsqueeze(0) + (upper - lower).unsqueeze(0) * t_rand\n",
        "    return t_vals  # in [0,1] param domain\n",
        "\n",
        "def sample_pdf(bins, weights, n_samples, device):\n",
        "    # bins: [N_rays, N_coarse] (edges), weights: [N_rays, N_coarse]\n",
        "    weights = weights + 1e-5\n",
        "    pdf = weights / torch.sum(weights, dim=-1, keepdim=True)\n",
        "    cdf = torch.cumsum(pdf, dim=-1)\n",
        "    cdf = torch.cat([torch.zeros_like(cdf[..., :1]), cdf], dim=-1)\n",
        "    u = torch.rand((cdf.shape[0], n_samples), device=device)\n",
        "    # inverse cdf (linear search)\n",
        "    inds = torch.searchsorted(cdf, u, right=True) - 1\n",
        "    inds = inds.clamp(0, cdf.shape[-1]-2)\n",
        "    cdf_g0 = torch.gather(cdf, 1, inds)\n",
        "    cdf_g1 = torch.gather(cdf, 1, inds+1)\n",
        "    bins_g0 = torch.gather(bins, 1, inds)\n",
        "    bins_g1 = torch.gather(bins, 1, inds+1)\n",
        "    t = (u - cdf_g0) / (cdf_g1 - cdf_g0 + 1e-8)\n",
        "    samples = bins_g0 + t * (bins_g1 - bins_g0)\n",
        "    return samples\n",
        "\n",
        "# combined renderer using coarse+fine\n",
        "class NeRFCoarseFine:\n",
        "    def __init__(self, device, N_coarse=64, N_fine=64, near=0.1, far=4.0, use_viewdirs=True):\n",
        "        self.device = device\n",
        "        self.Nc = N_coarse\n",
        "        self.Nf = N_fine\n",
        "        self.near = near; self.far = far\n",
        "        self.use_viewdirs = use_viewdirs\n",
        "        # encoders\n",
        "        self.pe_pos = PosEncoding(num_freqs=10)\n",
        "        self.pe_dir = PosEncoding(num_freqs=4)\n",
        "        # models\n",
        "        input_ch = 3 + 2*10*3\n",
        "        input_ch_dir = 3 + 2*4*3\n",
        "        self.coarse = NeRF_MLP(D=8, W=256, input_ch=input_ch, input_ch_dir=input_ch_dir, use_viewdirs=use_viewdirs).to(device)\n",
        "        self.fine = NeRF_MLP(D=8, W=256, input_ch=input_ch, input_ch_dir=input_ch_dir, use_viewdirs=use_viewdirs).to(device)\n",
        "\n",
        "    def render_rays(self, origins, dirs):\n",
        "        N = origins.shape[0]\n",
        "        device = self.device\n",
        "        # coarse stratified sampling in [near, far]\n",
        "        t_coarse = sample_stratified(N, self.Nc, self.near, self.far, device)  # [N, Nc], in [0,1]\n",
        "        z_coarse = self.near + (self.far - self.near) * t_coarse  # [N, Nc]\n",
        "        pts = origins.unsqueeze(1) + dirs.unsqueeze(1) * z_coarse.unsqueeze(-1)  # [N,Nc,3]\n",
        "        pts_flat = pts.reshape(-1,3)\n",
        "        # encode pos and dirs\n",
        "        pe_pts = self.pe_pos(torch.tensor(pts_flat, device=device))\n",
        "        viewdirs = dirs / torch.norm(dirs, dim=-1, keepdim=True)\n",
        "        viewdirs_enc = self.pe_dir(viewdirs).unsqueeze(1).expand(-1, self.Nc, -1).reshape(-1, viewdirs.shape[-1]*(2*4+1))\n",
        "        # forward coarse\n",
        "        rgb_c, sigma_c = self.coarse(pe_pts, viewdirs_enc.to(device))\n",
        "        rgb_c = rgb_c.view(N, self.Nc, 3)\n",
        "        sigma_c = sigma_c.view(N, self.Nc, 1)\n",
        "        # rendering coarse\n",
        "        comp_c, weights_c = volume_rendering(rgb_c, sigma_c, z_coarse, dirs)\n",
        "        bins = 0.5*(z_coarse[:, :-1] + z_coarse[:, 1:])  # [N, Nc-1]\n",
        "        weights_for_pdf = weights_c[:, :-1].detach()  # [N, Nc-1]\n",
        "        z_fine_norm = sample_pdf(bins, weights_for_pdf, self.Nf, device)  # [N, Nf] in [near, far]\n",
        "        z_all = torch.cat([z_coarse, z_fine_norm], dim=1)\n",
        "        z_all, _ = torch.sort(z_all, dim=1)\n",
        "        pts_all = origins.unsqueeze(1) + dirs.unsqueeze(1) * z_all.unsqueeze(-1)\n",
        "        pts_all_flat = pts_all.reshape(-1,3)\n",
        "        pe_pts_all = self.pe_pos(torch.tensor(pts_all_flat, device=device))\n",
        "        viewdirs_enc_all = self.pe_dir(viewdirs).unsqueeze(1).expand(-1, z_all.shape[1], -1).reshape(-1, viewdirs.shape[-1]*(2*4+1))\n",
        "        rgb_f, sigma_f = self.fine(pe_pts_all, viewdirs_enc_all.to(device))\n",
        "        rgb_f = rgb_f.view(N, z_all.shape[1], 3)\n",
        "        sigma_f = sigma_f.view(N, z_all.shape[1], 1)\n",
        "        comp_f, weights_f = volume_rendering(rgb_f, sigma_f, z_all, dirs)\n",
        "        return comp_f, weights_c, z_coarse, rgb_c\n"
      ],
      "id": "8d5JBpUv3uXy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2rnXBHh3uXy"
      },
      "outputs": [],
      "source": [
        "def get_ray_directions(H, W, focal):\n",
        "    i, j = torch.meshgrid(torch.arange(W), torch.arange(H), indexing='xy')\n",
        "    i = i.t().float(); j = j.t().float()\n",
        "    dirs = torch.stack([(i - W*0.5)/focal, -(j - H*0.5)/focal, -torch.ones_like(i)], -1)  # [H,W,3]\n",
        "    return dirs  # camera coords\n",
        "\n",
        "def sample_points_along_rays(origins, directions, near, far, N_samples):\n",
        "    # origins, directions: [num_rays, 3]\n",
        "    t_vals = torch.linspace(near, far, N_samples).to(origins.device)\n",
        "    t_vals = t_vals.expand(origins.shape[0], N_samples)\n",
        "    pts = origins.unsqueeze(1) + directions.unsqueeze(1) * t_vals.unsqueeze(-1)  # [num_rays, N_samples, 3]\n",
        "    return pts, t_vals\n",
        "\n",
        "def volume_rendering(rgb, sigma, z_vals, dirs):\n",
        "    # rgb: [num_rays, N_samples, 3], sigma: [num_rays, N_samples, 1]\n",
        "    deltas = z_vals[:,1:] - z_vals[:,:-1]  # [num_rays, N-1]\n",
        "    delta_last = 1e10 * torch.ones_like(deltas[:,:1])\n",
        "    deltas = torch.cat([deltas, delta_last], dim=1)  # [num_rays, N]\n",
        "    alpha = 1.0 - torch.exp(-sigma.squeeze(-1) * deltas)\n",
        "    weights = alpha * torch.cumprod(torch.cat([torch.ones((alpha.shape[0],1), device=alpha.device), 1.0 - alpha + 1e-10], dim=1), dim=1)[:,:-1]\n",
        "    # weights: [num_rays, N_samples]\n",
        "    comp_rgb = (weights.unsqueeze(-1) * rgb).sum(dim=1)  # [num_rays,3]\n",
        "    return comp_rgb, weights\n"
      ],
      "id": "p2rnXBHh3uXy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAhNX92t3uXz"
      },
      "outputs": [],
      "source": [
        "def load_transforms_for_asset(asset_folder):\n",
        "    tfp = os.path.join(asset_folder, \"transforms.json\")\n",
        "    if not os.path.exists(tfp):\n",
        "        return None\n",
        "    return json.load(open(tfp))\n",
        "\n",
        "def train_nerf_on_relit_enhanced(relit_root, out_dir, steps=2000, batch_rays=1024, N_coarse=64, N_fine=64, H=IMAGE_SIZE, W=IMAGE_SIZE):\n",
        "    ds = NeRFDataset(relit_root, img_size=H)\n",
        "    if len(ds) == 0:\n",
        "        print(\"No relit data found in\", relit_root); return\n",
        "    device_local = device\n",
        "    renderer = NeRFCoarseFine(device_local, N_coarse=N_coarse, N_fine=N_fine)\n",
        "    optimizer = torch.optim.Adam(list(renderer.coarse.parameters()) + list(renderer.fine.parameters()), lr=5e-4)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    ray_data = []\n",
        "    for it in ds.items:\n",
        "        img_t = transforms.ToTensor()(Image.open(it[\"path\"]).convert(\"RGB\").resize((W,H)))\n",
        "        pose = it[\"pose\"]\n",
        "        if pose is None:\n",
        "            pose_mat = np.eye(4).tolist()\n",
        "        else:\n",
        "            pose_mat = pose\n",
        "        camera_angle_x = 0.69\n",
        "        focal = 0.5 * W / math.tan(0.5 * camera_angle_x)\n",
        "        dirs_cam = get_ray_directions(H,W,focal).reshape(-1,3).to(device_local)\n",
        "        pose_mat = torch.tensor(pose_mat, dtype=torch.float32).to(device_local)\n",
        "        R = pose_mat[:3,:3]; t = pose_mat[:3,3]\n",
        "        dirs_world = (dirs_cam @ R.t())\n",
        "        origins = t.unsqueeze(0).expand(dirs_world.shape[0],3)\n",
        "        colors = img_t.permute(1,2,0).reshape(-1,3).to(device_local)\n",
        "        ray_data.append({\"origins\": origins, \"dirs\": dirs_world, \"colors\": colors})\n",
        "    print(\"Prepared ray data from\", len(ray_data), \"images.\")\n",
        "\n",
        "    for step in range(steps):\n",
        "        idx_img = random.randrange(len(ray_data))\n",
        "        rd = ray_data[idx_img]\n",
        "        num_rays_total = rd[\"dirs\"].shape[0]\n",
        "        sel_idx = torch.randperm(num_rays_total)[:batch_rays]\n",
        "        origins = rd[\"origins\"][sel_idx].to(device_local)\n",
        "        dirs = rd[\"dirs\"][sel_idx].to(device_local)\n",
        "        target_rgb = rd[\"colors\"][sel_idx].to(device_local)\n",
        "        comp_rgb, w_c, z_c, rgb_c = renderer.render_rays(origins, dirs)\n",
        "        loss = loss_fn(comp_rgb, target_rgb)\n",
        "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "        if step % 50 == 0:\n",
        "            print(f\"[NeRF] step {step}/{steps} loss {loss.item():.6f}\")\n",
        "    # save models\n",
        "    torch.save(renderer.coarse.state_dict(), os.path.join(out_dir, \"nerf_coarse.pth\"))\n",
        "    torch.save(renderer.fine.state_dict(), os.path.join(out_dir, \"nerf_fine.pth\"))\n",
        "    print(\"Saved NeRF coarse & fine.\")\n",
        "    return out_dir\n"
      ],
      "id": "NAhNX92t3uXz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2Q76MVA3uXz"
      },
      "outputs": [],
      "source": [
        "# 1) Relighting\n",
        "os.makedirs(RELIGHT_OUT, exist_ok=True)\n",
        "train_relighting(MANIFEST, RELIGHT_OUT, epochs=RELIGHT_EPOCHS, bs=RELIGHT_BS, image_size=IMAGE_SIZE, num_views=NUM_VIEWS)\n",
        "\n",
        "for asset in sorted(os.listdir(RELIGHT_OUT))[:5]:\n",
        "    print(\"Relit outputs for:\", asset, \"->\", os.listdir(os.path.join(RELIGHT_OUT, asset))[:5])\n",
        "\n",
        "# 2) Train NeRF\n",
        "os.makedirs(NERF_OUT, exist_ok=True)\n",
        "train_nerf_on_relit(RELIGHT_OUT, NERF_OUT, steps=NERF_EPOCHS, batch_rays=NERF_BATCH_RAYS, N_samples=NERF_N_SAMPLES, H=IMAGE_SIZE, W=IMAGE_SIZE)\n",
        "\n",
        "print(\"Pipeline finished.\")\n"
      ],
      "id": "k2Q76MVA3uXz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdWYEOka3uXz"
      },
      "outputs": [],
      "source": [
        "# Relighting\n",
        "\n",
        "def test_relighting(manifest_path, model_ckpt, out_dir, image_size=128, num_views=8):\n",
        "    ds = MultiViewRelightDataset(manifest_path, image_size=image_size, num_views=num_views)\n",
        "    dl = DataLoader(ds, batch_size=1, shuffle=False)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = RelightingModel().to(device)\n",
        "    model.load_state_dict(torch.load(model_ckpt, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(tqdm(dl, desc=\"relighting-test\")):\n",
        "            imgs = batch['images'].to(device)  # [1, V, 3, H, W]\n",
        "            ref = imgs[:, 0]\n",
        "            out = model(ref)\n",
        "\n",
        "            scene_dir = os.path.join(out_dir, f\"scene_{idx}\")\n",
        "            os.makedirs(scene_dir, exist_ok=True)\n",
        "\n",
        "            ref_img = ref[0].cpu().permute(1,2,0).numpy()\n",
        "            ref_img = (ref_img*255).astype(\"uint8\")\n",
        "            Image.fromarray(ref_img).save(os.path.join(scene_dir, \"input.png\"))\n",
        "\n",
        "            out_img = out[0].cpu().permute(1,2,0).numpy()\n",
        "            out_img = (out_img*255).astype(\"uint8\")\n",
        "            Image.fromarray(out_img).save(os.path.join(scene_dir, \"relit.png\"))\n",
        "\n",
        "    print(f\"Relit test images saved to {out_dir}\")\n",
        "\n",
        "\n",
        "# NeRF => Test\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "def test_nerf(model_ckpt, out_dir, res=64, num_samples=64):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    model = NeRF().to(device)\n",
        "    model.load_state_dict(torch.load(model_ckpt))\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    H, W = res, res\n",
        "    rays_o = torch.zeros(H*W, 3).to(device)  # مبدأ پرتوها (0,0,0)\n",
        "    dirs = []\n",
        "    for y in range(H):\n",
        "        for x in range(W):\n",
        "            dirs.append([ (x - W/2)/W, -(y - H/2)/H, -1.0 ])  # ساده: رو به -z\n",
        "    rays_d = torch.tensor(dirs, dtype=torch.float32).to(device)\n",
        "\n",
        "\n",
        "    rendered = []\n",
        "    for i in tqdm(range(0, H*W, 1024), desc=\"NeRF test rendering\"):\n",
        "        batch_rays_o = rays_o[i:i+1024]\n",
        "        batch_rays_d = rays_d[i:i+1024]\n",
        "\n",
        "        t_vals = torch.linspace(0., 1., steps=num_samples).to(device)\n",
        "        pts = batch_rays_o[:, None, :] + batch_rays_d[:, None, :] * t_vals[None,:,None]  # [N_rays, N_samples, 3]\n",
        "        pts_flat = pts.reshape(-1, 3)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            rgb = model(pts_flat)  # [N_rays*N_samples, 3]\n",
        "            rgb = rgb.view(batch_rays_o.shape[0], num_samples, 3)\n",
        "\n",
        "            rgb_final = rgb.mean(dim=1)\n",
        "\n",
        "        rendered.append(rgb_final.cpu())\n",
        "\n",
        "    rendered = torch.cat(rendered, dim=0).numpy().reshape(H, W, 3)\n",
        "    rendered = (rendered * 255).clip(0,255).astype(np.uint8)\n",
        "\n",
        "    out_path = os.path.join(out_dir, \"nerf_test.png\")\n",
        "    Image.fromarray(rendered).save(out_path)\n",
        "    print(f\"NeRF test image saved at {out_path}\")\n",
        "\n",
        "\n",
        "# MSE و PSNR\n",
        "\n",
        "def psnr(mse_loss):\n",
        "    return 10 * math.log10(1.0 / mse_loss)\n",
        "\n",
        "def evaluate_relighting(manifest_path, model_ckpt, image_size=128, num_samples=10):\n",
        "    ds = MultiViewRelightDataset(manifest_path, image_size=image_size)\n",
        "    dl = DataLoader(ds, batch_size=1, shuffle=True)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = RelightingModel().to(device)\n",
        "    model.load_state_dict(torch.load(model_ckpt))\n",
        "    model.eval()\n",
        "\n",
        "    loss_fn = nn.MSELoss()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(dl):\n",
        "            if i >= num_samples: break\n",
        "            imgs = batch['images'].to(device)\n",
        "            ref = imgs[:,0]\n",
        "            out = model(ref)\n",
        "            loss = loss_fn(out, ref)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / num_samples\n",
        "    print(f\"Relighting Eval → MSE: {avg_loss:.6f}, PSNR: {psnr(avg_loss):.2f} dB\")\n"
      ],
      "id": "XdWYEOka3uXz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfSD1nAI3uXz"
      },
      "outputs": [],
      "source": [
        "test_relighting(MANIFEST, os.path.join(RELIGHT_OUT, \"relighting_model.pth\"), \"/content/test_relighting\")\n",
        "evaluate_relighting(MANIFEST, os.path.join(RELIGHT_OUT, \"relighting_model.pth\"))\n",
        "\n",
        "test_nerf(os.path.join(NERF_OUT, \"nerf_model.pth\"), \"/content/test_nerf\")\n"
      ],
      "id": "lfSD1nAI3uXz"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}